{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "# Import my function\n",
    "from Normalization import Normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options\n",
    "mini_batch_size = 2880\n",
    "Delay = 8\n",
    "time_horizon = 1\n",
    "Training_MSE = []\n",
    "Training_MAE = []\n",
    "The_whole_prediction = []\n",
    "The_whole_actual = []\n",
    "pd.set_option(\"display.precision\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and prepare the data\n",
    "df = pd.read_excel('speed_volume_test.xlsx')\n",
    "data = pd.DataFrame(data=df)\n",
    "# data.info()\n",
    "\n",
    "# select the target time series\n",
    "target = ['Flow']\n",
    "features = data.drop(['Date'], axis=1).columns\n",
    "\n",
    "X_old = data[features].values\n",
    "T_old = data[target].values\n",
    "\n",
    "# Normalized the data based on the normalization function\n",
    "normalizedX = Normalization(X_old, type_of_normalization = 1) # Range from 1 to 4\n",
    "normalizedT = Normalization(T_old, type_of_normalization = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the input and target series\n",
    "X, T = [], []\n",
    "for k in range(len(normalizedT)-Delay-1):\n",
    "    a = normalizedX[k:(k+Delay), :]\n",
    "    flatted = a.flatten()\n",
    "    X.append(flatted) \n",
    "    T.append(normalizedT[k + Delay]) \n",
    "\n",
    "X = np.array(X)\n",
    "T = np.array(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data for create the model and the rest\n",
    "training_input = X[:mini_batch_size, :]\n",
    "training_output = T[:mini_batch_size, :]\n",
    "rest_of_input = X[mini_batch_size:-1, :]\n",
    "rest_of_output = T[mini_batch_size:-1, :]\n",
    "# convert to LSTM friendly format\n",
    "inputs = training_input.reshape((training_input.shape[0], training_input.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_loss = []\n",
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(20, input_shape=(inputs.shape[1], inputs.shape[2])))\n",
    "# model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(inputs, training_output, epochs=500, verbose=1, shuffle=False)\n",
    "history_loss = history_loss + model.history.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pair of (X, y) of the current minibatch/chunk\n",
    "for i in range(0, rest_of_input.shape[0], time_horizon):\n",
    "\n",
    "    X_train_mini = rest_of_input[i:i + time_horizon]\n",
    "    y_train_mini = rest_of_output[i:i + time_horizon]\n",
    "\n",
    "    prediction = []\n",
    "    for j in range(len(X_train_mini)):\n",
    "        testX = X_train_mini[j]\n",
    "        X_train_mini_reshaped = testX.reshape((1, testX.shape[0], 1))\n",
    "        Predicted = model.predict(X_train_mini_reshaped)\n",
    "        prediction = np.concatenate((prediction, Predicted.ravel()))\n",
    "\n",
    "    denormalization_actual = T_old.min() + (T_old.max() - T_old.min())*y_train_mini\n",
    "    denormalization_predict = T_old.min() + (T_old.max() - T_old.min())*prediction\n",
    "    MSE = mean_squared_error(denormalization_actual, denormalization_predict)\n",
    "    MAE = np.sum(np.abs(denormalization_actual -\n",
    "                        denormalization_predict))/time_horizon\n",
    "    Training_MSE.append(MSE)\n",
    "    Training_MAE.append(MAE)\n",
    "    The_whole_prediction = np.concatenate(\n",
    "        (The_whole_prediction, denormalization_predict.ravel()))\n",
    "    The_whole_actual = np.concatenate(\n",
    "        (The_whole_actual, denormalization_actual.ravel()))\n",
    "\n",
    "    # Update the training input and output\n",
    "    training_input = np.vstack((training_input[time_horizon:], X_train_mini))\n",
    "    training_output = np.vstack((training_output[time_horizon:], y_train_mini))\n",
    "\n",
    "    # convert to LSTM friendly format\n",
    "    inputs = training_input.reshape(\n",
    "        (training_input.shape[0], training_input.shape[1], 1))\n",
    "\n",
    "    model.fit(inputs, training_output, epochs=500,\n",
    "              verbose=1, shuffle=False)\n",
    "\n",
    "    # save the loss of this epoch to history_loss\n",
    "    # history_loss.append(model.history.history['loss'])\n",
    "    history_loss = history_loss + model.history.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the figure size in inches\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(18, 6))\n",
    "\n",
    "# Plot the predicted and actual values\n",
    "ax1.plot(The_whole_actual, label='Actual')\n",
    "ax1.plot(The_whole_prediction, label='Predicted')\n",
    "ax1.set_title('Comparison of Predicted and Actual Values')\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Flow')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot the training loss history\n",
    "ax2.plot(history_loss)\n",
    "ax2.set_title('Training Loss History')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "\n",
    "# Save the combined figure as a JPEG file\n",
    "# plt.savefig('combined_plots.jpg', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
